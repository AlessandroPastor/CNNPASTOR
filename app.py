import numpy as np
import os
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import LeakyReLU
import pandas as pd
from datetime import datetime

# Configuraci√≥n para mejores gr√°ficos
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = [10, 6]

print("=" * 60)
print("SISTEMA DE CLASIFICACI√ìN DE IM√ÅGENES DEPORTIVAS")
print("=" * 60)

# =============================================================================
# 1. CARGA Y PREPROCESAMIENTO DE DATOS
# =============================================================================
print("\nüìÅ FASE 1: CARGA DE IM√ÅGENES")
print("-" * 40)

# Ruta base del conjunto de im√°genes
base_dir = os.path.join(os.getcwd(), "sportimages")

# Listas para almacenar informaci√≥n
images = []
directories = []
dircount = []

print(f"Leyendo im√°genes desde: {base_dir}\n")

cant = 0
prev_root = None

# Recorre recursivamente todas las carpetas e im√°genes
for root, _, filenames in os.walk(base_dir):
    image_files = [f for f in filenames if re.search(r"\.(jpg|jpeg|png|bmp|tiff)$", f, re.IGNORECASE)]
    
    if image_files:
        directories.append(root)
        count_in_dir = 0
        
        for filename in image_files:
            filepath = os.path.join(root, filename)
            try:
                image = plt.imread(filepath)
                images.append(image)
                count_in_dir += 1
                cant += 1
                print(f"üì∏ Leyendo imagen {cant}: {filename}", end="\r")
            except Exception as e:
                print(f"\n‚ö†Ô∏è Error leyendo {filepath}: {e}")
        
        dircount.append(count_in_dir)
        print(f"\nüìÇ {root} ‚Üí {count_in_dir} im√°genes")

# Resumen final
print("\nüìä RESUMEN DE CARGA:")
print(f"   ‚Ä¢ Directorios le√≠dos: {len(directories)}")
print(f"   ‚Ä¢ Im√°genes por directorio: {dircount}")
print(f"   ‚Ä¢ Total de im√°genes: {sum(dircount)}")

# =============================================================================
# 2. CREACI√ìN DE ETIQUETAS Y METADATOS
# =============================================================================
print("\nüè∑Ô∏è FASE 2: CREACI√ìN DE ETIQUETAS")
print("-" * 40)

# CREAR LAS ETIQUETAS QUE FALTABAN
labels = []
indice = 0
for cantidad in dircount:
    for i in range(cantidad):
        labels.append(indice)
    indice = indice + 1

print(f"‚úÖ Etiquetas creadas: {len(labels)}")

deportes = []
indice = 0
for directorio in directories:
    name = directorio.split(os.sep)
    deporte_nombre = name[len(name)-1]
    print(f"   üéØ Clase {indice}: {deporte_nombre}")
    deportes.append(deporte_nombre)
    indice = indice + 1

# Convertir a arrays de numpy
y = np.array(labels)
X = np.array(images, dtype=np.uint8)

# Informaci√≥n de clases
classes = np.unique(y)
nClasses = len(classes)
print(f'\nüéØ INFORMACI√ìN DE CLASES:')
print(f'   ‚Ä¢ N√∫mero de clases: {nClasses}')
print(f'   ‚Ä¢ Clases: {classes}')

# =============================================================================
# 3. PREPARACI√ìN DE DATOS
# =============================================================================
print("\nüîß FASE 3: PREPARACI√ìN DE DATOS")
print("-" * 40)

# Dividir los datos
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42, stratify=train_y)

# Normalizar los datos
train_X = train_X.astype('float32') / 255.0
valid_X = valid_X.astype('float32') / 255.0
test_X = test_X.astype('float32') / 255.0

# Convertir etiquetas a one-hot encoding
train_label = to_categorical(train_y, nClasses)
valid_label = to_categorical(valid_y, nClasses)
test_Y_one_hot = to_categorical(test_y, nClasses)

print(f"üìê DIMENSIONES:")
print(f"   ‚Ä¢ Entrenamiento: {train_X.shape} -> {train_label.shape}")
print(f"   ‚Ä¢ Validaci√≥n: {valid_X.shape} -> {valid_label.shape}")
print(f"   ‚Ä¢ Prueba: {test_X.shape} -> {test_Y_one_hot.shape}")

# =============================================================================
# 4. VISUALIZACI√ìN DE DATOS
# =============================================================================
print("\nüìä FASE 4: VISUALIZACI√ìN DE DATOS")
print("-" * 40)

# Gr√°fico de distribuci√≥n de clases
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
class_distribution = [np.sum(train_y == i) for i in range(nClasses)]
bars = plt.bar(range(nClasses), class_distribution, color=plt.cm.Set3(np.linspace(0, 1, nClasses)))
plt.title('DISTRIBUCI√ìN DE CLASES - ENTRENAMIENTO', fontweight='bold')
plt.xlabel('Clases')
plt.ylabel('N√∫mero de Im√°genes')
plt.xticks(range(nClasses), [f'C{i}' for i in range(nClasses)])

# A√±adir valores en las barras
for bar, count in zip(bars, class_distribution):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
             str(count), ha='center', va='bottom')

# Ejemplos de im√°genes
plt.subplot(1, 2, 2)
if len(train_X) >= 6:
    # Mostrar primeras 6 im√°genes
    for i in range(6):
        plt.subplot(2, 3, i + 1)
        plt.imshow(train_X[i])
        plt.title(f'Clase: {train_y[i]}')
        plt.axis('off')
    plt.suptitle('EJEMPLOS DE IM√ÅGENES', fontweight='bold')

plt.tight_layout()
plt.show()

# =============================================================================
# 5. CONSTRUCCI√ìN DEL MODELO CNN
# =============================================================================
print("\nüß† FASE 5: CONSTRUCCI√ìN DEL MODELO CNN")
print("-" * 40)

INIT_LR = 1e-3
epochs = 6
batch_size = 64

input_shape = train_X.shape[1:]
print(f"   ‚Ä¢ Input shape: {input_shape}")
print(f"   ‚Ä¢ Tasa de aprendizaje: {INIT_LR}")
print(f"   ‚Ä¢ √âpocas: {epochs}")
print(f"   ‚Ä¢ Batch size: {batch_size}")

# Construir modelo
sport_model = Sequential()
sport_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same', input_shape=input_shape))
sport_model.add(LeakyReLU(alpha=0.1))
sport_model.add(MaxPooling2D((2, 2), padding='same'))
sport_model.add(Dropout(0.5))

sport_model.add(Flatten())
sport_model.add(Dense(32, activation='linear'))
sport_model.add(LeakyReLU(alpha=0.1))
sport_model.add(Dropout(0.5)) 
sport_model.add(Dense(nClasses, activation='softmax'))

sport_model.summary()

# Compilar modelo
sport_model.compile(
    loss=keras.losses.categorical_crossentropy, 
    optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR), 
    metrics=['accuracy']
)

# =============================================================================
# 6. ENTRENAMIENTO DEL MODELO
# =============================================================================
print("\nüöÄ FASE 6: ENTRENAMIENTO DEL MODELO")
print("-" * 40)

print("‚è≥ Iniciando entrenamiento...")
history = sport_model.fit(
    train_X, train_label, 
    batch_size=batch_size,
    epochs=epochs,
    verbose=1,
    validation_data=(valid_X, valid_label)
)

# =============================================================================
# 7. EVALUACI√ìN DEL MODELO
# =============================================================================
print("\nüìà FASE 7: EVALUACI√ìN DEL MODELO")
print("-" * 40)

# Guardar modelo
sport_model.save("sports_classifier.h5")
print("üíæ Modelo guardado como 'sports_classifier.h5'")

# Evaluar modelo
test_eval = sport_model.evaluate(test_X, test_Y_one_hot, verbose=1)
print(f'\nüéØ RESULTADOS EN PRUEBA:')
print(f'   ‚Ä¢ P√©rdida: {test_eval[0]:.4f}')
print(f'   ‚Ä¢ Precisi√≥n: {test_eval[1]:.4f} ({test_eval[1]*100:.2f}%)')

# Predicciones
predicted_classes = sport_model.predict(test_X, verbose=0)
predicted_classes = np.argmax(predicted_classes, axis=1)

# Reporte de clasificaci√≥n
target_names = [f"{deportes[i] if i < len(deportes) else f'Clase {i}'}" for i in range(nClasses)]
print("\nüìã REPORTE DE CLASIFICACI√ìN:")
print(classification_report(test_y, predicted_classes, target_names=target_names))

# =============================================================================
# 8. VISUALIZACI√ìN DE RESULTADOS
# =============================================================================
print("\nüìä FASE 8: VISUALIZACI√ìN DE RESULTADOS")
print("-" * 40)

H = history.history
acc_key = 'accuracy' if 'accuracy' in H else 'acc'
val_acc_key = 'val_accuracy' if 'val_accuracy' in H else 'val_acc'

epochs_range = range(1, len(H['loss']) + 1)

# Crear figura con m√∫ltiples subplots
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

# 1. GR√ÅFICO DE PRECISI√ìN
ax1.plot(epochs_range, H[acc_key], 'o-', linewidth=2, markersize=6, 
         label='Precisi√≥n Entrenamiento', color='#2E86AB')
ax1.plot(epochs_range, H[val_acc_key], 's-', linewidth=2, markersize=6, 
         label='Precisi√≥n Validaci√≥n', color='#A23B72')
ax1.set_title('EVOLUCI√ìN DE LA PRECISI√ìN', fontsize=14, fontweight='bold')
ax1.set_xlabel('√âpoca')
ax1.set_ylabel('Precisi√≥n')
ax1.legend()
ax1.grid(True, alpha=0.3)
ax1.set_ylim(0, 1)

# 2. GR√ÅFICO DE P√âRDIDA
ax2.plot(epochs_range, H['loss'], 'o-', linewidth=2, markersize=6, 
         label='P√©rdida Entrenamiento', color='#F18F01')
ax2.plot(epochs_range, H['val_loss'], 's-', linewidth=2, markersize=6, 
         label='P√©rdida Validaci√≥n', color='#C73E1D')
ax2.set_title('EVOLUCI√ìN DE LA P√âRDIDA', fontsize=14, fontweight='bold')
ax2.set_xlabel('√âpoca')
ax2.set_ylabel('P√©rdida')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. MATRIZ DE CONFUSI√ìN
cm = confusion_matrix(test_y, predicted_classes)
im = ax3.imshow(cm, interpolation='nearest', cmap='Blues')
ax3.set_title('MATRIZ DE CONFUSI√ìN', fontsize=14, fontweight='bold')
plt.colorbar(im, ax=ax3)

# Etiquetas de la matriz de confusi√≥n
tick_marks = np.arange(nClasses)
ax3.set_xticks(tick_marks)
ax3.set_yticks(tick_marks)
ax3.set_xticklabels([f'C{i}' for i in range(nClasses)])
ax3.set_yticklabels([f'C{i}' for i in range(nClasses)])

# A√±adir valores en las celdas
thresh = cm.max() / 2.
for i in range(nClasses):
    for j in range(nClasses):
        ax3.text(j, i, format(cm[i, j], 'd'),
                horizontalalignment="center",
                color="white" if cm[i, j] > thresh else "black")

ax3.set_ylabel('Etiqueta Real')
ax3.set_xlabel('Etiqueta Predicha')

# 4. M√âTRICAS PRINCIPALES
ax4.axis('off')
metrics_text = f"""
RESUMEN DEL MODELO

Precisi√≥n Final: {test_eval[1]:.4f}
P√©rdida Final: {test_eval[0]:.4f}

Total √âpocas: {epochs}
Batch Size: {batch_size}
Tasa Aprendizaje: {INIT_LR}

Clases: {nClasses}
Im√°genes: {len(X)}
"""
ax4.text(0.1, 0.9, metrics_text, transform=ax4.transAxes, fontsize=12,
         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))

plt.tight_layout()
plt.savefig('resultados_entrenamiento.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# 9. REPORTE FINAL
# =============================================================================
print("\n" + "="*60)
print("INFORME FINAL DEL ENTRENAMIENTO")
print("="*60)

print(f"\nüìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"üìä Datos procesados: {len(X)} im√°genes, {nClasses} clases")
print(f"üéØ Precisi√≥n final: {test_eval[1]:.4f} ({test_eval[1]*100:.2f}%)")
print(f"üìâ P√©rdida final: {test_eval[0]:.4f}")

print(f"\nüèÜ CLASIFICACI√ìN POR RENDIMIENTO:")
if test_eval[1] >= 0.9:
    print("   ‚úÖ EXCELENTE - Modelo de alto rendimiento")
elif test_eval[1] >= 0.7:
    print("   üëç BUENO - Modelo funcional")
elif test_eval[1] >= 0.5:
    print("   ‚ö†Ô∏è  REGULAR - Podr√≠a necesitar mejoras")
else:
    print("   ‚ùå BAJO - Se recomienda revisar datos y modelo")

print(f"\nüíæ Archivos generados:")
print(f"   ‚Ä¢ sports_classifier.h5 - Modelo entrenado")
print(f"   ‚Ä¢ resultados_entrenamiento.png - Gr√°ficos de resultados")

print("\n" + "="*60)